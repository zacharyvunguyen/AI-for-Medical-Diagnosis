{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# W1 Review Code"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "#import util"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Checking Data Leakage\n",
    "* Write a function to check whether there is leakage between two datasets.\n",
    "* We'll use this to make sure there are no patients in the test set that are also present in either the train or validation sets."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###  Identifying Overlapping Records\n",
    "Function: **check_for_leakage**: Return True if there any patients are in both df1 and df2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "    \"\"\"\n",
    "    Args:\n",
    "        df1 (dataframe): dataframe describing first dataset\n",
    "        df2 (dataframe): dataframe describing second dataset\n",
    "        patient_col (str): string name of column with patient IDs\n",
    "\n",
    "    Returns:\n",
    "        leakage (bool): True if there is leakage, otherwise False\n",
    "    \"\"\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def check_for_leakage(df1, df2, patient_col):\n",
    "    df1_patients_unique = set(df1[patient_col].values)\n",
    "    df2_patients_unique = set(df2[patient_col].values)\n",
    "\n",
    "    patients_in_both_groups = df1_patients_unique.intersection(df2_patients_unique)\n",
    "\n",
    "    # leakage contains true if there is patient overlap, otherwise false.\n",
    "    leakage = len(patients_in_both_groups) != 0 # boolean (true if there is at least 1 patient in both groups)\n",
    "\n",
    "    return leakage"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If we get False for both, then we're ready to start preparing the datasets for training. Remember to always check for data leakage!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "outputs": [],
   "source": [
    "def zach_check_for_leakage(df1, df2, input_col):\n",
    "    df1_patients_unique = set(df1[input_col].values)\n",
    "    df2_patients_unique = set(df2[input_col].values)\n",
    "\n",
    "    patients_in_both_groups = df1_patients_unique.intersection(df2_patients_unique)\n",
    "\n",
    "    # leakage contains true if there is patient overlap, otherwise false.\n",
    "    leakage = len(patients_in_both_groups) != 0 # boolean (true if there is at least 1 patient in both groups)\n",
    "\n",
    "    if leakage is False:\n",
    "        return print(f'Leakage: {leakage}.There is No Leakage between the datasets. Ready to start preparing the datasets for training')\n",
    "    else:\n",
    "        return print(f'Leakage: {leakage}. There are {len(patients_in_both_groups)} records in both the datasets: {patients_in_both_groups}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run the next cell to check if there are patients in both train and test or in both valid and test."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "outputs": [],
   "source": [
    "#Case 1\n",
    "case1_train_df = pd.DataFrame({'PatientId': [0, 1, 2,3,4,5,6,8]})\n",
    "case1_valid_df= pd.DataFrame({'PatientId': [9, 10, 11,12]})\n",
    "case1_test_df = pd.DataFrame({'PatientId': [6, 0, 4,21,22,23,35]})\n",
    "zach_check_for_leakage(case1_train_df, case1_test_df, 'PatientId')\n",
    "zach_check_for_leakage(case1_valid_df, case1_test_df, 'PatientId')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Check & Remove Overlapping Records\n",
    "* Write a function `remove_overlapping_records` to check and remove overlapping records if existed between two datasets.\n",
    "    * Removed record from the second set: `df2.drop(df2_overlap_idxs, inplace=True`\n",
    "* We'll use this to make sure there are no record in the second set that are also present in the first set."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "    \"\"\"\n",
    "    Args:\n",
    "        df1 (dataframe): dataframe describing first dataset\n",
    "        df2 (dataframe): dataframe describing second dataset\n",
    "        input_col (str): string name of column need for checking overlapping records.\n",
    "\n",
    "    Returns:\n",
    "       ...\n",
    "    \"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [],
   "source": [
    "def remove_overlapping_records (df1, df2, input_col):\n",
    "    ids_df1 = df1[input_col].values\n",
    "    ids_df2 = df2[input_col].values\n",
    "\n",
    "    df2_original_len=len(df2)\n",
    "\n",
    "    ids_df1_set = set(ids_df1)\n",
    "    ids_df2_set = set(ids_df2)\n",
    "\n",
    "    records_overlap=  list(ids_df1_set.intersection(ids_df2_set))\n",
    "    n_overlap = len(records_overlap)\n",
    "\n",
    "    df1_overlap_idxs = []\n",
    "    df2_overlap_idxs = []\n",
    "\n",
    "    for idx in range(n_overlap):\n",
    "        df1_overlap_idxs.extend(df1.index[df1[input_col] == records_overlap[idx]].tolist())\n",
    "        df2_overlap_idxs.extend(df2.index[df2[input_col] == records_overlap[idx]].tolist())\n",
    "\n",
    "    leakage = n_overlap != 0 # boolean (true if there is at least 1 patient in both groups)\n",
    "\n",
    "    if leakage is False:\n",
    "        return print(f'{leakage}: There is No Leakage between the datasets. Ready to start preparing the datasets for training')\n",
    "    else:\n",
    "        return \\\n",
    "            print(\n",
    "                f'Leakage: {leakage}. There are {n_overlap} records in both the datasets: {records_overlap}'), print(\n",
    "                f'First datase - indices of overlapping records:{df1_overlap_idxs}'), print(\n",
    "                f'Second datase - indices of overlapping records:{df2_overlap_idxs}'), df2.drop(df2_overlap_idxs, inplace=True), print(\n",
    "                f'Removed {len(df2_overlap_idxs)} overlapping record from the second dataframe.'), print(\n",
    "                f'Original lenght of the second dataframe: {df2_original_len}'), print(\n",
    "                f'New lenght of the second dataframe: {len(df2)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "outputs": [],
   "source": [
    "#Case 1\n",
    "case1_train_df = pd.DataFrame({'PatientId': [0, 1, 2,3,4,5,6,8]})\n",
    "case1_valid_df= pd.DataFrame({'PatientId': [9, 10, 11,12]})\n",
    "case1_test_df = pd.DataFrame({'PatientId': [6, 0, 4,21,22,4,0,23,35]})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leakage: True. There are 3 records in both the datasets: [0, 4, 6]\n",
      "First datase - indices of overlapping records:[0, 4, 6]\n",
      "Second datase - indices of overlapping records:[1, 6, 2, 5, 0]\n",
      "Removed 5 overlapping record from the second dataframe.\n",
      "Original lenght of the second dataframe: 9\n",
      "New lenght of the second dataframe: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": "(None, None, None, None, None, None, None)"
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_overlapping_records(case1_train_df, case1_test_df, 'PatientId')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leakage: False.There is No Leakage between the datasets. Ready to start preparing the datasets for training\n"
     ]
    }
   ],
   "source": [
    "zach_check_for_leakage(case1_valid_df, case1_test_df, 'PatientId')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1000 rows and 16 columns in the training dataframe\n"
     ]
    },
    {
     "data": {
      "text/plain": "              Image  Atelectasis  Cardiomegaly  Consolidation  Edema  \\\n0  00008270_015.png            0             0              0      0   \n1  00029855_001.png            1             0              0      0   \n2  00001297_000.png            0             0              0      0   \n3  00012359_002.png            0             0              0      0   \n4  00017951_001.png            0             0              0      0   \n\n   Effusion  Emphysema  Fibrosis  Hernia  Infiltration  Mass  Nodule  \\\n0         0          0         0       0             0     0       0   \n1         1          0         0       0             1     0       0   \n2         0          0         0       0             0     0       0   \n3         0          0         0       0             0     0       0   \n4         0          0         0       0             1     0       0   \n\n   PatientId  Pleural_Thickening  Pneumonia  Pneumothorax  \n0       8270                   0          0             0  \n1      29855                   0          0             0  \n2       1297                   1          0             0  \n3      12359                   0          0             0  \n4      17951                   0          0             0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image</th>\n      <th>Atelectasis</th>\n      <th>Cardiomegaly</th>\n      <th>Consolidation</th>\n      <th>Edema</th>\n      <th>Effusion</th>\n      <th>Emphysema</th>\n      <th>Fibrosis</th>\n      <th>Hernia</th>\n      <th>Infiltration</th>\n      <th>Mass</th>\n      <th>Nodule</th>\n      <th>PatientId</th>\n      <th>Pleural_Thickening</th>\n      <th>Pneumonia</th>\n      <th>Pneumothorax</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00008270_015.png</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8270</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00029855_001.png</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>29855</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00001297_000.png</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1297</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00012359_002.png</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12359</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00017951_001.png</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>17951</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read csv file containing training data\n",
    "train_df = pd.read_csv(\"data/nih/train-small.csv\")\n",
    "# Print first 5 rows\n",
    "print(f'There are {train_df.shape[0]} rows and {train_df.shape[1]} columns in the training dataframe')\n",
    "train_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 109 rows and 16 columns in the validation dataframe\n"
     ]
    },
    {
     "data": {
      "text/plain": "              Image  Atelectasis  Cardiomegaly  Consolidation  Edema  \\\n0  00027623_007.png            0             0              0      1   \n1  00028214_000.png            0             0              0      0   \n2  00022764_014.png            0             0              0      0   \n3  00020649_001.png            1             0              0      0   \n4  00022283_023.png            0             0              0      0   \n\n   Effusion  Emphysema  Fibrosis  Hernia  Infiltration  Mass  Nodule  \\\n0         1          0         0       0             0     0       0   \n1         0          0         0       0             0     0       0   \n2         0          0         0       0             0     0       0   \n3         1          0         0       0             0     0       0   \n4         0          0         0       0             0     0       0   \n\n   PatientId  Pleural_Thickening  Pneumonia  Pneumothorax  \n0      27623                   0          0             0  \n1      28214                   0          0             0  \n2      22764                   0          0             0  \n3      20649                   0          0             0  \n4      22283                   0          0             0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image</th>\n      <th>Atelectasis</th>\n      <th>Cardiomegaly</th>\n      <th>Consolidation</th>\n      <th>Edema</th>\n      <th>Effusion</th>\n      <th>Emphysema</th>\n      <th>Fibrosis</th>\n      <th>Hernia</th>\n      <th>Infiltration</th>\n      <th>Mass</th>\n      <th>Nodule</th>\n      <th>PatientId</th>\n      <th>Pleural_Thickening</th>\n      <th>Pneumonia</th>\n      <th>Pneumothorax</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00027623_007.png</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>27623</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00028214_000.png</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>28214</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00022764_014.png</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>22764</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00020649_001.png</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>20649</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00022283_023.png</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>22283</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read csv file containing validation data\n",
    "valid_df = pd.read_csv(\"data/nih/valid-small.csv\")\n",
    "# Print first 5 rows\n",
    "print(f'There are {valid_df.shape[0]} rows and {valid_df.shape[1]} columns in the validation dataframe')\n",
    "valid_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leakage: True. There are 11 records in both the datasets: {20290, 27618, 9925, 10888, 22764, 19981, 18253, 4461, 28208, 8760, 7482}\n"
     ]
    }
   ],
   "source": [
    "zach_check_for_leakage(train_df,valid_df,'PatientId')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leakage: True. There are 11 records in both the datasets: [20290, 27618, 9925, 10888, 22764, 19981, 18253, 4461, 28208, 8760, 7482]\n",
      "First datase - indices of overlapping records:[306, 186, 797, 98, 408, 917, 327, 913, 10, 51, 276]\n",
      "Second datase - indices of overlapping records:[104, 88, 65, 13, 2, 41, 56, 70, 26, 75, 20, 52, 55]\n",
      "Removed 13 overlapping record from the second dataframe.\n",
      "Original lenght of the second dataframe: 109\n",
      "New lenght of the second dataframe: 96\n"
     ]
    },
    {
     "data": {
      "text/plain": "(None, None, None, None, None, None, None)"
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_overlapping_records(train_df,valid_df,'PatientId')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "outputs": [
    {
     "data": {
      "text/plain": "16"
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "outputs": [
    {
     "data": {
      "text/plain": "(96, 16)"
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preparing Images\n",
    "### Generator for training set\n",
    "1. Normalize the mean and standard deviation of the data\n",
    "2. Shuffle the input after each epoch.\n",
    "3. Set the image size to be 320px by 320px"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\"\"\"\n",
    "    Return generator for training set, normalizing using batch\n",
    "    statistics.\n",
    "\n",
    "    Args:\n",
    "      train_df (dataframe): dataframe specifying training data.\n",
    "      image_dir (str): directory where image files are held.\n",
    "      x_col (str): name of column in df that holds filenames.\n",
    "      y_cols (list): list of strings that hold y labels for images.\n",
    "      batch_size (int): images per batch to be fed into model during training.\n",
    "      seed (int): random seed.\n",
    "      target_w (int): final width of input images.\n",
    "      target_h (int): final height of input images.\n",
    "\n",
    "    Returns:\n",
    "        train_generator (DataFrameIterator): iterator over training set\n",
    "    \"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_train_generator(df, image_dir, x_col, y_cols, shuffle=True, batch_size=8, seed=1, target_w = 320, target_h = 320):\n",
    "\n",
    "    print(\"getting train generator...\")\n",
    "    # normalize images\n",
    "    image_generator = ImageDataGenerator(\n",
    "        samplewise_center=True,\n",
    "        samplewise_std_normalization= True)\n",
    "\n",
    "    # flow from directory with specified batch size\n",
    "    # and target image size\n",
    "    generator = image_generator.flow_from_dataframe(\n",
    "            dataframe=df,\n",
    "            directory=image_dir,\n",
    "            x_col=x_col,\n",
    "            y_col=y_cols,\n",
    "            class_mode=\"raw\",\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            seed=seed,\n",
    "            target_size=(target_w,target_h))\n",
    "\n",
    "    return generator"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generator for testing & validating dataset\n",
    "**Why can't we use the same generator as for the training data?**\n",
    "\n",
    "Look back at the generator we wrote for the training data.\n",
    "\n",
    "* It normalizes each image per batch, meaning that it uses batch statistics.\n",
    "* We should not do this with the test and validation data, since in a real life scenario we don't process incoming images a batch at a time (we process one image at a time).\n",
    "* Knowing the average per batch of test data would effectively give our model an advantage.\n",
    "    * The model should not have any information about the test data.\n",
    "\n",
    "What we need to do is normalize incoming test data using the statistics computed from the training set.\n",
    "* We implement this in the function below.\n",
    "* There is one technical note. Ideally, we would want to compute our sample mean and standard deviation using the entire training set.\n",
    "* However, since this is extremely large, that would be very time consuming.\n",
    "* In the interest of time, we'll take a random sample of the dataset and calcualte the sample mean and sample standard deviation.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Return generator for validation set and test test set using\n",
    "    normalization statistics from training set.\n",
    "\n",
    "    Args:\n",
    "      valid_df (dataframe): dataframe specifying validation data.\n",
    "      test_df (dataframe): dataframe specifying test data.\n",
    "      train_df (dataframe): dataframe specifying training data.\n",
    "      image_dir (str): directory where image files are held.\n",
    "      x_col (str): name of column in df that holds filenames.\n",
    "      y_cols (list): list of strings that hold y labels for images.\n",
    "      sample_size (int): size of sample to use for normalization statistics.\n",
    "      batch_size (int): images per batch to be fed into model during training.\n",
    "      seed (int): random seed.\n",
    "      target_w (int): final width of input images.\n",
    "      target_h (int): final height of input images.\n",
    "\n",
    "    Returns:\n",
    "        test_generator (DataFrameIterator) and valid_generator: iterators over test set and validation set respectively\n",
    "    \"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "outputs": [],
   "source": [
    "IMAGE_DIR = \"nih/images-small/\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Remove a list of values from another list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "outputs": [],
   "source": [
    "def remove_list_from_list(original_list,remove_columns_list):\n",
    "    for item in original_list:\n",
    "        if item in remove_columns_list:\n",
    "            original_list.remove(item)\n",
    "    return original_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "outputs": [
    {
     "data": {
      "text/plain": "['Image',\n 'Atelectasis',\n 'Cardiomegaly',\n 'Consolidation',\n 'Edema',\n 'Effusion',\n 'Emphysema',\n 'Fibrosis',\n 'Hernia',\n 'Infiltration',\n 'Mass',\n 'Nodule',\n 'PatientId',\n 'Pleural_Thickening',\n 'Pneumonia',\n 'Pneumothorax']"
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_df.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "outputs": [
    {
     "data": {
      "text/plain": "['Image', 'PatientId']"
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_columns_list = ['Image','PatientId']\n",
    "remove_columns_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "outputs": [
    {
     "data": {
      "text/plain": "['Atelectasis',\n 'Cardiomegaly',\n 'Consolidation',\n 'Edema',\n 'Effusion',\n 'Emphysema',\n 'Fibrosis',\n 'Hernia',\n 'Infiltration',\n 'Mass',\n 'Nodule',\n 'Pleural_Thickening',\n 'Pneumonia',\n 'Pneumothorax']"
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_list_from_list(list(train_df.columns),remove_columns_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_test_and_valid_generator(valid_df, test_df, train_df, image_dir, x_col, y_cols, sample_size=100, batch_size=8, seed=1, target_w = 320, target_h = 320):\n",
    "    print(\"getting train and valid generators...\")\n",
    "    # get generator to sample dataset\n",
    "    raw_train_generator = ImageDataGenerator().flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        directory=IMAGE_DIR,\n",
    "        x_col=\"Image\",\n",
    "        y_col=labels,\n",
    "        class_mode=\"raw\",\n",
    "        batch_size=sample_size,\n",
    "        shuffle=True,\n",
    "        target_size=(target_w, target_h))\n",
    "\n",
    "    # get data sample\n",
    "    batch = raw_train_generator.next()\n",
    "    data_sample = batch[0]\n",
    "\n",
    "    # use sample to fit mean and std for test set generator\n",
    "    image_generator = ImageDataGenerator(\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization= True)\n",
    "\n",
    "    # fit generator to sample from training data\n",
    "    image_generator.fit(data_sample)\n",
    "\n",
    "    # get test generator\n",
    "    valid_generator = image_generator.flow_from_dataframe(\n",
    "            dataframe=valid_df,\n",
    "            directory=image_dir,\n",
    "            x_col=x_col,\n",
    "            y_col=y_cols,\n",
    "            class_mode=\"raw\",\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            seed=seed,\n",
    "            target_size=(target_w,target_h))\n",
    "\n",
    "    test_generator = image_generator.flow_from_dataframe(\n",
    "            dataframe=test_df,\n",
    "            directory=image_dir,\n",
    "            x_col=x_col,\n",
    "            y_col=y_cols,\n",
    "            class_mode=\"raw\",\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            seed=seed,\n",
    "            target_size=(target_w,target_h))\n",
    "    return valid_generator, test_generator"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}